# ğŸ“ Projet MPI/OpenMP - Neural Network Parallel

## ğŸ“¦ Contenu du Projet Complet

### Structure des Fichiers

```
neural_network_parallel/
â”‚
â”œâ”€â”€ ğŸ“„ CODE SOURCE
â”‚   â”œâ”€â”€ neural_network.c           # Implementation principale MPI+OpenMP
â”‚   â””â”€â”€ neural_network_serial.c    # Version sÃ©quentielle (baseline)
â”‚
â”œâ”€â”€ ğŸ”§ BUILD & EXECUTION
â”‚   â”œâ”€â”€ Makefile                    # Compilation et exÃ©cution
â”‚   â”œâ”€â”€ setup.sh                    # Script d'installation automatique
â”‚   â””â”€â”€ benchmark.py                # Benchmarking automatisÃ© (Python)
â”‚
â”œâ”€â”€ ğŸ“š DOCUMENTATION
â”‚   â”œâ”€â”€ README.md                   # Guide de dÃ©marrage rapide
â”‚   â”œâ”€â”€ RAPPORT.md                  # Rapport acadÃ©mique complet
â”‚   â”œâ”€â”€ EVALUATION.md               # Grille d'Ã©valuation pour enseignants
â”‚   â”œâ”€â”€ EXPECTED_RESULTS.md         # Exemples de sorties attendues
â”‚   â””â”€â”€ TROUBLESHOOTING.md          # Guide de dÃ©pannage
â”‚
â””â”€â”€ ğŸ“Š RÃ‰SULTATS (gÃ©nÃ©rÃ©s aprÃ¨s exÃ©cution)
    â”œâ”€â”€ output_*.txt                # Logs d'exÃ©cution
    â””â”€â”€ benchmark_results.txt       # RÃ©sultats de performance
```

---

## ğŸš€ DÃ©marrage Rapide (5 minutes)

### 1. Installation des DÃ©pendances

**MÃ©thode Automatique (RecommandÃ©e) :**
```bash
cd neural_network_parallel
sudo bash setup.sh
```

**MÃ©thode Manuelle :**
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install -y build-essential openmpi-bin libopenmpi-dev libomp-dev python3

# macOS
brew install gcc open-mpi python3
```

### 2. Compilation

```bash
make
# âœ“ Compile les versions parallÃ¨le et sÃ©quentielle
```

### 3. ExÃ©cution

```bash
# Test rapide
make run

# Benchmark complet
make benchmark

# Comparaison serial vs parallel
make compare
```

---

## ğŸ“‹ Architecture du RÃ©seau

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  Input Layer (784)  â†’  Hidden1 (128)  â†’  Hidden2 (64)  â”‚
â”‚    [28Ã—28 image]         [ReLU]           [ReLU]       â”‚
â”‚                                                         â”‚
â”‚                    â†’  Output Layer (10)                 â”‚
â”‚                         [Softmax]                       â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**TÃ¢che :** Forward pass (infÃ©rence) pour classification d'images
**Dataset :** SynthÃ©tique (MNIST-like)
**Taille du problÃ¨me :** 1000 Ã©chantillons par dÃ©faut

---

## ğŸ¯ StratÃ©gie de ParallÃ©lisation

### Niveau 1 : MPI (Data Parallelism)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dataset    â”‚  1000 samples
â”‚  (N=1000)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚  MPI_Scatter
       â”‚
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚       â”‚        â”‚        â”‚
â”Œâ”€â”€â–¼â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”
â”‚Rank0â”‚ â”‚Rank1â”‚  â”‚Rank2â”‚  â”‚Rank3â”‚
â”‚ 250 â”‚ â”‚ 250 â”‚  â”‚ 250 â”‚  â”‚ 250 â”‚
â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜
```

**Chaque processus MPI :**
- ReÃ§oit un batch distinct d'Ã©chantillons
- PossÃ¨de une copie complÃ¨te du rÃ©seau
- Calcule les prÃ©dictions indÃ©pendamment

### Niveau 2 : OpenMP (Task Parallelism)
```
Dans chaque processus MPI :

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Matrix Ã— Vector Product       â”‚
â”‚                                â”‚
â”‚  Thread 0: Rows 0-31          â”‚
â”‚  Thread 1: Rows 32-63         â”‚  #pragma omp parallel for
â”‚  Thread 2: Rows 64-95         â”‚
â”‚  Thread 3: Rows 96-127        â”‚
â”‚                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Chaque thread OpenMP :**
- Calcule un sous-ensemble de neurones (lignes de la matrice)
- OpÃ¨re sur des donnÃ©es distinctes (pas de conflits)
- Synchronisation automatique Ã  la fin de la boucle

---

## ğŸ”¬ CaractÃ©ristiques Techniques

### Points Forts de l'ImplÃ©mentation

âœ… **Correctness**
- RÃ©sultats dÃ©terministes (mÃªme seed â†’ mÃªmes prÃ©dictions)
- Validation : serial vs parallel identiques
- Pas de race conditions (vÃ©rifiÃ© avec Thread Sanitizer)
- Gestion mÃ©moire propre (pas de fuites)

âœ… **MPI Decomposition**
- Distribution Ã©quilibrÃ©e des donnÃ©es (load balancing)
- Communications minimales (gather uniquement en fin)
- Tous les ranks actifs (pas d'idle time)
- Utilisation idiomatique de MPI (collective ops)

âœ… **OpenMP Parallelism**
- ParallÃ©lisation aux bons endroits (matrix-vector products)
- Clauses appropriÃ©es (`private`, `schedule(static)`)
- Pas de race conditions (variables locales, indices distincts)
- Overhead minimal (rÃ©utilisation du thread pool)

âœ… **Performance**
- Speedup attendu : 6-7x avec 8 workers (75-85% efficacitÃ©)
- ScalabilitÃ© : quasi-linÃ©aire jusqu'Ã  4-8 workers
- Benchmark automatisÃ© pour validation

âœ… **Code Quality**
- Documentation Doxygen
- Structure modulaire
- Commentaires explicatifs
- SÃ©paration compute/communication

---

## ğŸ“Š RÃ©sultats Attendus

### Configuration de Test
- **SystÃ¨me :** 8 cÅ“urs (Intel/AMD)
- **Compilation :** `-O3 -march=native -fopenmp`
- **Dataset :** 1000 Ã©chantillons

### Performance Typique

| Config | Processes | Threads | Time (s) | Speedup | Efficiency |
|--------|-----------|---------|----------|---------|------------|
| Serial | 1         | 1       | 0.128    | 1.00x   | 100%       |
| Hybrid | 2         | 2       | 0.038    | 3.39x   | 85%        |
| Hybrid | 4         | 2       | 0.021    | 6.24x   | 78%        |
| Max    | 4         | 4       | 0.018    | 7.06x   | 44%        |

**Observations :**
- âœ… Speedup quasi-linÃ©aire jusqu'Ã  6-8 workers
- âš ï¸ EfficacitÃ© dÃ©croÃ®t avec trop de threads (overhead)
- âœ… Configuration optimale : 4 processus Ã— 2 threads

---

## ğŸ“ CritÃ¨res d'Ã‰valuation

### Grille AcadÃ©mique (sur 100 points)

| CritÃ¨re                     | Points | Justification                          |
|-----------------------------|--------|----------------------------------------|
| **1. Correctness**          | 20     | Fonctionnement sans erreur            |
| **2. MPI Decomposition**    | 20     | Distribution efficace, pas d'idle     |
| **3. OpenMP Parallelism**   | 20     | Pas de race conditions, speedup       |
| **4. Performance**          | 15     | Analyse de speedup vs thÃ©orique       |
| **5. Code Clarity**         | 10     | Documentation, structure              |
| **6. ExpÃ©riences**          | 10     | Protocole, rÃ©sultats, analyse         |
| **7. Conclusion**           | 5      | Perspectives d'amÃ©lioration           |
| **TOTAL**                   | **100**|                                        |

---

## ğŸ“– Utilisation des Documents

### Pour l'Ã‰tudiant

1. **README.md** â†’ DÃ©marrage rapide (5-10 min)
2. **neural_network.c** â†’ Comprendre l'implÃ©mentation
3. **benchmark.py** â†’ Lancer les tests de performance
4. **RAPPORT.md** â†’ Remplir avec vos rÃ©sultats expÃ©rimentaux
5. **TROUBLESHOOTING.md** â†’ En cas de problÃ¨me

### Pour l'Enseignant

1. **EVALUATION.md** â†’ Grille de correction dÃ©taillÃ©e
2. **EXPECTED_RESULTS.md** â†’ Valider les sorties
3. **RAPPORT.md** â†’ Ã‰valuer la comprÃ©hension thÃ©orique

---

## ğŸ”§ Commandes Essentielles

```bash
# Installation
sudo bash setup.sh

# Compilation
make                    # Compile tout
make clean && make      # Recompilation propre

# ExÃ©cution
make run                # Test rapide (4 procs)
make test               # Test correctness
make compare            # Serial vs Parallel
make benchmark          # Tous les configs
python3 benchmark.py    # Benchmark dÃ©taillÃ©

# Debugging
make CFLAGS="-g -fopenmp -O0"  # Debug mode
gdb ./neural_network           # Debugger
valgrind ./neural_network      # Memory check

# Performance
perf record mpirun -np 4 ./neural_network
perf report

# Info
make info               # Voir config systÃ¨me
make help               # Aide
```

---

## âœ… Checklist Projet Complet

### Avant Soumission

- [ ] Compilation sans warnings
- [ ] ExÃ©cution sans segfault
- [ ] Speedup > 3x avec 4 processus
- [ ] RÃ©sultats dans RAPPORT.md
- [ ] Code commentÃ© (Doxygen)
- [ ] Benchmarks exÃ©cutÃ©s
- [ ] README Ã  jour
- [ ] Pas de fuites mÃ©moire (valgrind)
- [ ] Pas de race conditions (Thread Sanitizer)

### QualitÃ© AcadÃ©mique

- [ ] Architecture justifiÃ©e
- [ ] Choix de parallÃ©lisation expliquÃ©s
- [ ] RÃ©sultats expÃ©rimentaux complets
- [ ] Analyse thÃ©orique vs pratique
- [ ] Perspectives d'amÃ©lioration
- [ ] RÃ©fÃ©rences bibliographiques

---

## ğŸŒŸ Points Forts du Projet

1. **Pertinence IA** : Application directe au domaine
2. **ComplexitÃ© Ã©quilibrÃ©e** : Ni trop simple, ni trop complexe
3. **ExtensibilitÃ©** : Facile d'ajouter CNN, plus de couches, etc.
4. **PÃ©dagogique** : Illustre bien MPI + OpenMP
5. **Professionnel** : Code quality production-ready
6. **Reproductible** : Scripts automatisÃ©s, documentation complÃ¨te

---

## ğŸš€ Perspectives d'AmÃ©lioration

### Court Terme (1 semaine)
- [ ] Pipeline parallÃ¨le (overlap compute/comm)
- [ ] Cache blocking (tiling)
- [ ] SIMD avec intrinsics AVX

### Moyen Terme (1 mois)
- [ ] Extension Ã  CNNs
- [ ] Mixed precision (FP16)
- [ ] Load balancing dynamique

### Long Terme (Recherche)
- [ ] Model parallelism (distribuer poids)
- [ ] Asynchronous SGD (training)
- [ ] Multi-node scaling (cluster)

---

## ğŸ“ Support

**Questions Techniques :**
- Voir TROUBLESHOOTING.md
- Forum OpenMPI : https://www.open-mpi.org/community/help/
- Stack Overflow : Tags [mpi] [openmp]

**Questions AcadÃ©miques :**
- Contacter votre enseignant
- Heures de permanence

---

## ğŸ“„ Licence

Projet acadÃ©mique - Master 2 Intelligence Artificielle  
Libre d'utilisation pour l'enseignement et l'apprentissage

---

## ğŸ‰ Conclusion

Ce projet vous permet de maÃ®triser :
âœ… Programmation hybride MPI/OpenMP  
âœ… Optimisation de code parallÃ¨le  
âœ… Analyse de performance  
âœ… Application Ã  l'IA  

**Temps estimÃ© :** 4-8 heures (selon expÃ©rience)

**Bon courage ! ğŸš€**

---

**Version :** 1.0  
**Date :** DÃ©cembre 2024  
**Contact :** [Votre enseignant]
