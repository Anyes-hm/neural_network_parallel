# Parallel Neural Network - MPI/OpenMP Project

**Master 2 Intelligence Artificielle - Projet AcadÃ©mique**

## ğŸ“‹ Description

ImplÃ©mentation d'un forward pass parallÃ¨le pour un rÃ©seau de neurones MLP utilisant :
- **MPI** : Distribution des batches d'entrÃ©e entre processus
- **OpenMP** : ParallÃ©lisation des opÃ©rations matricielles

## ğŸ¯ Architecture du RÃ©seau

```
Input (784) â†’ Hidden1 (128) â†’ Hidden2 (64) â†’ Output (10)
   [28Ã—28]      [ReLU]          [ReLU]       [Softmax]
```

## ğŸš€ Installation Rapide

### PrÃ©requis

**Ubuntu/Debian :**
```bash
sudo apt update
sudo apt install -y build-essential cmake
sudo apt install -y openmpi-bin openmpi-common libopenmpi-dev
sudo apt install -y libomp-dev python3
```

**macOS (avec Homebrew) :**
```bash
brew install gcc open-mpi libomp
```

**Windows (WSL2) :**
```bash
# Dans WSL Ubuntu
sudo apt update && sudo apt install -y build-essential openmpi-bin libopenmpi-dev
```

### VÃ©rification de l'Installation

```bash
mpicc --version    # Doit afficher OpenMPI
gcc --version      # Doit supporter OpenMP
```

## ğŸ”§ Compilation

```bash
# Compilation standard
make

# Compilation avec informations de debug
make CFLAGS="-g -fopenmp -Wall"

# Nettoyage
make clean
```

## â–¶ï¸ ExÃ©cution

### ExÃ©cution Simple

```bash
# Avec 4 processus MPI (configuration par dÃ©faut)
make run

# Ou directement
mpirun -np 4 ./neural_network
```

### Personnalisation du Nombre de Threads

```bash
# 4 processus MPI, 2 threads OpenMP par processus
OMP_NUM_THREADS=2 mpirun -np 4 ./neural_network

# 2 processus, 4 threads chacun
OMP_NUM_THREADS=4 mpirun -np 2 ./neural_network
```

### Benchmarking Automatique

```bash
# Lance plusieurs configurations et compare les performances
make benchmark

# Ou avec le script Python (plus dÃ©taillÃ©)
python3 benchmark.py
```

## ğŸ“Š Exemple de Sortie

```
====================================
Parallel Neural Network Forward Pass
====================================
MPI Processes: 4
OpenMP Threads per process: 2
Total Samples: 1000
Samples per rank: 250
Network: 784 -> 128 -> 64 -> 10
====================================

Performance Results:
--------------------
Total inference time: 0.023456 seconds
Throughput: 42634.21 samples/second
Time per sample: 0.000234 seconds

Sample Predictions (first 3 samples):
-------------------------------------
Sample 0: [0.087, 0.104, 0.089, 0.112, 0.095, 0.098, 0.103, 0.091, 0.109, 0.102]
          Predicted class: 3 (confidence: 11.20%)
...
```

## ğŸ“ˆ Analyse des Performances

### Configuration RecommandÃ©e

Pour un systÃ¨me avec 8 cÅ“urs :
```bash
# Option 1 : Maximiser le parallÃ©lisme MPI
OMP_NUM_THREADS=1 mpirun -np 8 ./neural_network

# Option 2 : Ã‰quilibrÃ© (gÃ©nÃ©ralement meilleur)
OMP_NUM_THREADS=2 mpirun -np 4 ./neural_network

# Option 3 : Favoriser OpenMP
OMP_NUM_THREADS=4 mpirun -np 2 ./neural_network
```

### Speedup Attendu

| Configuration | Speedup Attendu | EfficacitÃ© |
|--------------|----------------|------------|
| 1 proc Ã— 1 thread | 1.0x (baseline) | 100% |
| 2 proc Ã— 2 threads | 3.0-3.5x | 75-87% |
| 4 proc Ã— 2 threads | 5.5-6.5x | 69-81% |

## ğŸ§ª Tests et Validation

### Test de Correctness

```bash
# Compare rÃ©sultats sÃ©quentiels vs parallÃ¨les
make test
```

### Profiling (Optionnel)

```bash
# Avec gprof
gcc -pg -fopenmp neural_network.c -o neural_network -lm -fopenmp
mpirun -np 4 ./neural_network
gprof neural_network gmon.out > analysis.txt

# Avec perf (Linux)
perf record mpirun -np 4 ./neural_network
perf report
```

## ğŸ“ Structure du Projet

```
neural_network_parallel/
â”œâ”€â”€ neural_network.c    # Code source principal
â”œâ”€â”€ Makefile           # Compilation et exÃ©cution
â”œâ”€â”€ benchmark.py       # Script de benchmarking avancÃ©
â”œâ”€â”€ RAPPORT.md         # Rapport acadÃ©mique complet
â””â”€â”€ README.md          # Ce fichier
```

## ğŸ› DÃ©pannage

### Erreur : "mpicc: command not found"
```bash
# VÃ©rifier l'installation MPI
which mpicc
# Si absent, rÃ©installer
sudo apt install openmpi-bin libopenmpi-dev
```

### Erreur : "undefined reference to omp_*"
```bash
# VÃ©rifier le support OpenMP
echo |cpp -fopenmp -dM |grep -i open
# Ajouter -fopenmp aux flags de compilation
```

### Performance MÃ©diocre
1. VÃ©rifier que le CPU n'est pas throttlÃ© :
   ```bash
   cpupower frequency-info  # Linux
   ```
2. DÃ©sactiver hyperthreading pour mesures :
   ```bash
   echo off | sudo tee /sys/devices/system/cpu/smt/control
   ```
3. Isoler les cÅ“urs :
   ```bash
   taskset -c 0-7 mpirun -np 4 ./neural_network
   ```

## ğŸ“š Ressources

- **Documentation MPI :** https://www.open-mpi.org/doc/
- **Documentation OpenMP :** https://www.openmp.org/specifications/
- **Tutoriels :** https://computing.llnl.gov/tutorials/

## ğŸ“ Ã‰valuation AcadÃ©mique

Ce projet est Ã©valuÃ© selon :
1. âœ… Correctness (fonctionnement correct)
2. âœ… MPI decomposition (pas de ranks inactifs, communications efficaces)
3. âœ… OpenMP parallelism (pas de race conditions)
4. âœ… Performance et speedup (analyse comparative)
5. âœ… Code clarity (commentaires, structure)
6. âœ… ExpÃ©riences et analyse (benchmarks, justifications)
7. âœ… Conclusion (perspectives d'amÃ©lioration)

## ğŸ“ Rapport

Le rapport acadÃ©mique complet est disponible dans `RAPPORT.md`. Il contient :
- Analyse thÃ©orique de la parallÃ©lisation
- DÃ©tails d'implÃ©mentation
- RÃ©sultats expÃ©rimentaux
- Perspectives d'amÃ©lioration

## ğŸ“§ Contact

Pour questions acadÃ©miques, contactez votre enseignant.

## ğŸ“„ Licence

Projet acadÃ©mique - Master 2 IA

---

**Conseil :** Commencez par `make run` pour une exÃ©cution rapide, puis utilisez `benchmark.py` pour une analyse approfondie des performances.
